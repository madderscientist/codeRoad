# ANN神经网络
学校请了个牛津的老师在线教机器学习，听完ann就根据课上讲的手搓了一个。因为html可视化好，而且js语法灵活，就用了前端。功能是函数拟合。

- 创建时间：2022年9月6日，21:45:51
- 目的：巩固ann基础知识，实现任意函数拟合。
- 思路：[神经网络基本原理](https://space.bilibili.com/152254793/)。用一维数组表示每层的权值和bias。固定了激活函数为leak_relu。难点在于反向传播，需要推导一会。
- 使用：点击画布，即为输入一个训练点(x,y)，神经网络正向传播再反向传播完成一次权值更新，然后再根据此时正向传播的值画出图像。按住键盘可以反复训练上一次点击的点。可以在输入框键入目标函数，点击“确定”后，点击“训练1000次”即取1000个目标函数图像上的随机点为训练数据训练神经网络。创建ANN时，构造函数输入是一维数组，长度代表层数，值代表那一层有几个节点。<br>
http://htmlpreview.github.io/?https://github.com/madderscientist/codeRoad/blob/main/ANN/ann.html
- 成果：可以看到训练网络的一些现象：<br>
    **训练集数据量要大**：如果单靠人点击画布，训练量还是过少，效果不明显。（所以设置了目标函数，自动训练，向它逼近。）<br>
    **训练方法**：不能先一个点训练很多次再换一个点训练很多次。应该所有数据一批一批训练很多次。比如先点击100次A点，再点击100次B点，会发现A点似乎被“忘掉了”，结果和只输入B点训练差不多，而且B点还会过拟合；如果AB交替训练100次效果就好很多。<br>
    **步长（学习率）**：如果用频率较大的三角函数为目标函数，让ann去逼近，会发现最终取了均值，峰谷被磨平了，好像“滤波”了一样。这是步长设置的原因（太大了），限制了神经网络准确性进一步上升。步长设置过大了，图形震荡会很夸张，权值甚至会超过js允许的最大数。但是设小了出效果很慢。<br>
    **隐藏层设置**：理论上隐藏层越多越好，图形越细腻，但是发现运行缓慢。目前中间设了5层感觉差不多。而且隐藏层越多似乎对学习率越敏感，稍微大一点数组就爆了。
